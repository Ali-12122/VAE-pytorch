{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc4dd615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision \n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec3de22",
   "metadata": {},
   "source": [
    "This is a set of convenience functions to use instead of using the layers with thier hyperparamters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e191503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(channels_in, channels_out): \n",
    "    return nn.Conv2d(channels_in, channels_out, kernel_size = 3, stride = 1, padding = 'same', bias = False)\n",
    "\n",
    "def pool(): \n",
    "    return nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "\n",
    "def conv1x1(channels_in, channels_out): \n",
    "    return nn.Conv2d(channels_in, channels_out, kernel_size = 1, stride = 1, padding = 'same')\n",
    "\n",
    "def bn(channels_in): \n",
    "    return nn.BatchNorm2d(channels_in)\n",
    "\n",
    "def relu():\n",
    "    return nn.ReLU(inplace = True)\n",
    "\n",
    "def up():\n",
    "    return nn.Upsample(scale_factor = 2)\n",
    "\n",
    "def convUp(channels_in, channels_out): \n",
    "    return nn.Conv2d(channels_in, channels_out, kernel_size = 3, stride = 1, padding = 'same', bias = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b367bbe7",
   "metadata": {},
   "source": [
    "This a Sequential Module for a single block in the encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ddc7c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class down_Sample_Block(nn.Sequential):\n",
    "    def __init__(self, channels_in, channels_out):\n",
    "        super(down_Sample_Block, self).__init__()\n",
    "        self.add_module('conv1', conv(channels_in, channels_out))\n",
    "        self.add_module('conv2', conv(channels_out, channels_out))\n",
    "        self.add_module('conv3', conv(channels_out, channels_out))\n",
    "        self.add_module('conv4', conv(channels_out, channels_out))\n",
    "        self.add_module('norm', bn(channels_out))\n",
    "        self.add_module('relu', relu())\n",
    "        self.add_module('pool', pool())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9616dc",
   "metadata": {},
   "source": [
    "This a Sequential Module for a single block in the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2041a881",
   "metadata": {},
   "outputs": [],
   "source": [
    "class up_Sample_Block(nn.Sequential):\n",
    "    def __init__(self, channels_in, channels_out):\n",
    "        super(up_Sample_Block, self).__init__()\n",
    "        self.add_module('upSample', up())\n",
    "        self.add_module('conv1', convUp(channels_in, channels_out))\n",
    "        self.add_module('conv2', convUp(channels_out, channels_out))\n",
    "        self.add_module('conv3', convUp(channels_out, channels_out))\n",
    "        self.add_module('conv4', convUp(channels_out, channels_out))\n",
    "        self.add_module('norm', bn(channels_out))\n",
    "        self.add_module('relu', relu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc90fc93",
   "metadata": {},
   "source": [
    "Sequential module for the encoder block as a whole, it is designed to halve the height and width of the image, and double the number of channels, until it reaches (batch, channels, 1, 1).\n",
    "\n",
    "It is then passed through a conv_1x1 to reduce channels to 128, then it is flattened to remove the height and width dimensions (last two)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84810bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Sequential):\n",
    "    def __init__(self, encoder_output_length = 128):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.add_module('layer_1', down_Sample_Block(3, 8)) # 64\n",
    "        self.add_module('layer_2', down_Sample_Block(8, 16)) # 32\n",
    "        self.add_module('layer_3', down_Sample_Block(16, 32)) # 16\n",
    "        self.add_module('layer_4', down_Sample_Block(32, 64)) # 8\n",
    "        self.add_module('layer_5', down_Sample_Block(64, 128)) # 4\n",
    "        self.add_module('layer_6', down_Sample_Block(128, 256)) # 2\n",
    "        self.add_module('layer_7', down_Sample_Block(256, 256)) # 1\n",
    "\n",
    "        self.add_module('conv1x1', conv1x1(256, encoder_output_length))\n",
    "        self.add_module('flatten', nn.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020a9a1a",
   "metadata": {},
   "source": [
    "Module for the bottleneck block, it is the part where the mean and standard deviation layers are found, and where the reparameterization occurs.\n",
    "\n",
    "The output of the reconstruction has dimensions of (batch_size, channels), so inorder to make it suitable for the decoder, it is unsqueezed at dimensions 2 and 3 (the height and width dimensions are added again just like they were removed at the end of the encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "880294d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        latent_vec_len = 32,\n",
    "        encoder_output_length = 128,\n",
    "        decoder_input_length = 256\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.add_module('mean_layer', nn.Linear(encoder_output_length, latent_vec_len)),\n",
    "        self.add_module('standard_deviation_layer', nn.Linear(encoder_output_length, latent_vec_len)),\n",
    "        self.add_module('output_linear_layer', nn.Linear(latent_vec_len, decoder_input_length))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean = self.mean_layer(x)\n",
    "        standard_deviation = self.standard_deviation_layer(x)\n",
    "        epsilon = torch.randn_like(standard_deviation)\n",
    "        \n",
    "        x_reparameterized = mean + standard_deviation*epsilon\n",
    "        x_reconstructed = self.output_linear_layer(x_reparameterized)\n",
    "        \n",
    "        x_reconstructed = torch.unsqueeze(x_reconstructed, 2)\n",
    "        x_reconstructed = torch.unsqueeze(x_reconstructed, 3)\n",
    "        \n",
    "        return x_reconstructed, mean, standard_deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63a4d61",
   "metadata": {},
   "source": [
    "Sequential module for the decoder block as a whole, works in opposite fashion to the encoder.\n",
    "\n",
    "It is designed to take a tensor of dimensions (batch, channels, 1, 1) and double its height and width, and halve the number of channels, until it reaches (batch, 3, 128, 128)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd548f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Sequential):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.add_module('layer_1', up_Sample_Block(256, 256)) # 2\n",
    "        self.add_module('layer_2', up_Sample_Block(256, 128)) # 4\n",
    "        self.add_module('layer_3', up_Sample_Block(128, 64)) # 8\n",
    "        self.add_module('layer_4', up_Sample_Block(64, 32)) # 16\n",
    "        self.add_module('layer_5', up_Sample_Block(32, 16)) # 32\n",
    "        self.add_module('layer_6', up_Sample_Block(16, 8)) # 64\n",
    "        self.add_module('layer_7', up_Sample_Block(8, 3)) # 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776656df",
   "metadata": {},
   "source": [
    "Module for the VAE itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5122168",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.add_module('encoder', Encoder())\n",
    "        self.add_module('bottleneck', Bottleneck())\n",
    "        self.add_module('decoder', Decoder())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x, mean, standard_deviation = self.bottleneck(x)\n",
    "        x = self.decoder(x) \n",
    "        return x, mean, standard_deviation\n",
    "    \n",
    "    def generate(self, device):\n",
    "        with torch.no_grad():\n",
    "            x = torch.randn(1, 128)\n",
    "            x = x.to(device)\n",
    "            x, _, _ = self.bottleneck(x)\n",
    "            x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d59b3b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edefb599",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dda1e4e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "VAE                                      [128, 3, 128, 128]        --\n",
       "├─Encoder: 1-1                           [128, 128]                --\n",
       "│    └─down_Sample_Block: 2-1            [128, 8, 64, 64]          --\n",
       "│    │    └─Conv2d: 3-1                  [128, 8, 128, 128]        216\n",
       "│    │    └─Conv2d: 3-2                  [128, 8, 128, 128]        576\n",
       "│    │    └─Conv2d: 3-3                  [128, 8, 128, 128]        576\n",
       "│    │    └─Conv2d: 3-4                  [128, 8, 128, 128]        576\n",
       "│    │    └─BatchNorm2d: 3-5             [128, 8, 128, 128]        16\n",
       "│    │    └─ReLU: 3-6                    [128, 8, 128, 128]        --\n",
       "│    │    └─MaxPool2d: 3-7               [128, 8, 64, 64]          --\n",
       "│    └─down_Sample_Block: 2-2            [128, 16, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-8                  [128, 16, 64, 64]         1,152\n",
       "│    │    └─Conv2d: 3-9                  [128, 16, 64, 64]         2,304\n",
       "│    │    └─Conv2d: 3-10                 [128, 16, 64, 64]         2,304\n",
       "│    │    └─Conv2d: 3-11                 [128, 16, 64, 64]         2,304\n",
       "│    │    └─BatchNorm2d: 3-12            [128, 16, 64, 64]         32\n",
       "│    │    └─ReLU: 3-13                   [128, 16, 64, 64]         --\n",
       "│    │    └─MaxPool2d: 3-14              [128, 16, 32, 32]         --\n",
       "│    └─down_Sample_Block: 2-3            [128, 32, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-15                 [128, 32, 32, 32]         4,608\n",
       "│    │    └─Conv2d: 3-16                 [128, 32, 32, 32]         9,216\n",
       "│    │    └─Conv2d: 3-17                 [128, 32, 32, 32]         9,216\n",
       "│    │    └─Conv2d: 3-18                 [128, 32, 32, 32]         9,216\n",
       "│    │    └─BatchNorm2d: 3-19            [128, 32, 32, 32]         64\n",
       "│    │    └─ReLU: 3-20                   [128, 32, 32, 32]         --\n",
       "│    │    └─MaxPool2d: 3-21              [128, 32, 16, 16]         --\n",
       "│    └─down_Sample_Block: 2-4            [128, 64, 8, 8]           --\n",
       "│    │    └─Conv2d: 3-22                 [128, 64, 16, 16]         18,432\n",
       "│    │    └─Conv2d: 3-23                 [128, 64, 16, 16]         36,864\n",
       "│    │    └─Conv2d: 3-24                 [128, 64, 16, 16]         36,864\n",
       "│    │    └─Conv2d: 3-25                 [128, 64, 16, 16]         36,864\n",
       "│    │    └─BatchNorm2d: 3-26            [128, 64, 16, 16]         128\n",
       "│    │    └─ReLU: 3-27                   [128, 64, 16, 16]         --\n",
       "│    │    └─MaxPool2d: 3-28              [128, 64, 8, 8]           --\n",
       "│    └─down_Sample_Block: 2-5            [128, 128, 4, 4]          --\n",
       "│    │    └─Conv2d: 3-29                 [128, 128, 8, 8]          73,728\n",
       "│    │    └─Conv2d: 3-30                 [128, 128, 8, 8]          147,456\n",
       "│    │    └─Conv2d: 3-31                 [128, 128, 8, 8]          147,456\n",
       "│    │    └─Conv2d: 3-32                 [128, 128, 8, 8]          147,456\n",
       "│    │    └─BatchNorm2d: 3-33            [128, 128, 8, 8]          256\n",
       "│    │    └─ReLU: 3-34                   [128, 128, 8, 8]          --\n",
       "│    │    └─MaxPool2d: 3-35              [128, 128, 4, 4]          --\n",
       "│    └─down_Sample_Block: 2-6            [128, 256, 2, 2]          --\n",
       "│    │    └─Conv2d: 3-36                 [128, 256, 4, 4]          294,912\n",
       "│    │    └─Conv2d: 3-37                 [128, 256, 4, 4]          589,824\n",
       "│    │    └─Conv2d: 3-38                 [128, 256, 4, 4]          589,824\n",
       "│    │    └─Conv2d: 3-39                 [128, 256, 4, 4]          589,824\n",
       "│    │    └─BatchNorm2d: 3-40            [128, 256, 4, 4]          512\n",
       "│    │    └─ReLU: 3-41                   [128, 256, 4, 4]          --\n",
       "│    │    └─MaxPool2d: 3-42              [128, 256, 2, 2]          --\n",
       "│    └─down_Sample_Block: 2-7            [128, 256, 1, 1]          --\n",
       "│    │    └─Conv2d: 3-43                 [128, 256, 2, 2]          589,824\n",
       "│    │    └─Conv2d: 3-44                 [128, 256, 2, 2]          589,824\n",
       "│    │    └─Conv2d: 3-45                 [128, 256, 2, 2]          589,824\n",
       "│    │    └─Conv2d: 3-46                 [128, 256, 2, 2]          589,824\n",
       "│    │    └─BatchNorm2d: 3-47            [128, 256, 2, 2]          512\n",
       "│    │    └─ReLU: 3-48                   [128, 256, 2, 2]          --\n",
       "│    │    └─MaxPool2d: 3-49              [128, 256, 1, 1]          --\n",
       "│    └─Conv2d: 2-8                       [128, 128, 1, 1]          32,896\n",
       "│    └─Flatten: 2-9                      [128, 128]                --\n",
       "├─Bottleneck: 1-2                        [128, 256, 1, 1]          --\n",
       "│    └─Linear: 2-10                      [128, 32]                 4,128\n",
       "│    └─Linear: 2-11                      [128, 32]                 4,128\n",
       "│    └─Linear: 2-12                      [128, 256]                8,448\n",
       "├─Decoder: 1-3                           [128, 3, 128, 128]        --\n",
       "│    └─up_Sample_Block: 2-13             [128, 256, 2, 2]          --\n",
       "│    │    └─Upsample: 3-50               [128, 256, 2, 2]          --\n",
       "│    │    └─Conv2d: 3-51                 [128, 256, 2, 2]          589,824\n",
       "│    │    └─Conv2d: 3-52                 [128, 256, 2, 2]          589,824\n",
       "│    │    └─Conv2d: 3-53                 [128, 256, 2, 2]          589,824\n",
       "│    │    └─Conv2d: 3-54                 [128, 256, 2, 2]          589,824\n",
       "│    │    └─BatchNorm2d: 3-55            [128, 256, 2, 2]          512\n",
       "│    │    └─ReLU: 3-56                   [128, 256, 2, 2]          --\n",
       "│    └─up_Sample_Block: 2-14             [128, 128, 4, 4]          --\n",
       "│    │    └─Upsample: 3-57               [128, 256, 4, 4]          --\n",
       "│    │    └─Conv2d: 3-58                 [128, 128, 4, 4]          294,912\n",
       "│    │    └─Conv2d: 3-59                 [128, 128, 4, 4]          147,456\n",
       "│    │    └─Conv2d: 3-60                 [128, 128, 4, 4]          147,456\n",
       "│    │    └─Conv2d: 3-61                 [128, 128, 4, 4]          147,456\n",
       "│    │    └─BatchNorm2d: 3-62            [128, 128, 4, 4]          256\n",
       "│    │    └─ReLU: 3-63                   [128, 128, 4, 4]          --\n",
       "│    └─up_Sample_Block: 2-15             [128, 64, 8, 8]           --\n",
       "│    │    └─Upsample: 3-64               [128, 128, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-65                 [128, 64, 8, 8]           73,728\n",
       "│    │    └─Conv2d: 3-66                 [128, 64, 8, 8]           36,864\n",
       "│    │    └─Conv2d: 3-67                 [128, 64, 8, 8]           36,864\n",
       "│    │    └─Conv2d: 3-68                 [128, 64, 8, 8]           36,864\n",
       "│    │    └─BatchNorm2d: 3-69            [128, 64, 8, 8]           128\n",
       "│    │    └─ReLU: 3-70                   [128, 64, 8, 8]           --\n",
       "│    └─up_Sample_Block: 2-16             [128, 32, 16, 16]         --\n",
       "│    │    └─Upsample: 3-71               [128, 64, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-72                 [128, 32, 16, 16]         18,432\n",
       "│    │    └─Conv2d: 3-73                 [128, 32, 16, 16]         9,216\n",
       "│    │    └─Conv2d: 3-74                 [128, 32, 16, 16]         9,216\n",
       "│    │    └─Conv2d: 3-75                 [128, 32, 16, 16]         9,216\n",
       "│    │    └─BatchNorm2d: 3-76            [128, 32, 16, 16]         64\n",
       "│    │    └─ReLU: 3-77                   [128, 32, 16, 16]         --\n",
       "│    └─up_Sample_Block: 2-17             [128, 16, 32, 32]         --\n",
       "│    │    └─Upsample: 3-78               [128, 32, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-79                 [128, 16, 32, 32]         4,608\n",
       "│    │    └─Conv2d: 3-80                 [128, 16, 32, 32]         2,304\n",
       "│    │    └─Conv2d: 3-81                 [128, 16, 32, 32]         2,304\n",
       "│    │    └─Conv2d: 3-82                 [128, 16, 32, 32]         2,304\n",
       "│    │    └─BatchNorm2d: 3-83            [128, 16, 32, 32]         32\n",
       "│    │    └─ReLU: 3-84                   [128, 16, 32, 32]         --\n",
       "│    └─up_Sample_Block: 2-18             [128, 8, 64, 64]          --\n",
       "│    │    └─Upsample: 3-85               [128, 16, 64, 64]         --\n",
       "│    │    └─Conv2d: 3-86                 [128, 8, 64, 64]          1,152\n",
       "│    │    └─Conv2d: 3-87                 [128, 8, 64, 64]          576\n",
       "│    │    └─Conv2d: 3-88                 [128, 8, 64, 64]          576\n",
       "│    │    └─Conv2d: 3-89                 [128, 8, 64, 64]          576\n",
       "│    │    └─BatchNorm2d: 3-90            [128, 8, 64, 64]          16\n",
       "│    │    └─ReLU: 3-91                   [128, 8, 64, 64]          --\n",
       "│    └─up_Sample_Block: 2-19             [128, 3, 128, 128]        --\n",
       "│    │    └─Upsample: 3-92               [128, 8, 128, 128]        --\n",
       "│    │    └─Conv2d: 3-93                 [128, 3, 128, 128]        216\n",
       "│    │    └─Conv2d: 3-94                 [128, 3, 128, 128]        81\n",
       "│    │    └─Conv2d: 3-95                 [128, 3, 128, 128]        81\n",
       "│    │    └─Conv2d: 3-96                 [128, 3, 128, 128]        81\n",
       "│    │    └─BatchNorm2d: 3-97            [128, 3, 128, 128]        6\n",
       "│    │    └─ReLU: 3-98                   [128, 3, 128, 128]        --\n",
       "==========================================================================================\n",
       "Total params: 8,505,033\n",
       "Trainable params: 8,505,033\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 36.15\n",
       "==========================================================================================\n",
       "Input size (MB): 25.17\n",
       "Forward/backward pass size (MB): 1908.87\n",
       "Params size (MB): 34.02\n",
       "Estimated Total Size (MB): 1968.05\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "model = model\n",
    "batch_size = 128\n",
    "summary(model, input_size=(batch_size, 3, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5afa23eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class dataset(Dataset):\n",
    "    def __init__(\n",
    "        self, img_dir,\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(size=(128, 128)),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ]),\n",
    "        target_transform = transforms.Resize(size=(128, 128))\n",
    "    ):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.img_dir))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        os.chdir(self.img_dir)\n",
    "        img_path = self.img_dir + \"\\\\\\\\\" + str(idx+1) + \".jpg\"\n",
    "        # img_path = os.path.join(self.img_dir, str(idx) + \".JPEG\")\n",
    "        image = read_image(img_path)\n",
    "        image = image.to(torch.float32)\n",
    "        image = self.transform(image)\n",
    "        label = image        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c867d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 3e-7\n",
    "batch_size = 1\n",
    "num_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ed70096",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"E:\\\\College\\\\FCAI-4th Year\\\\First Term\\\\Generative Adversarial Networks\\\\Assginments\\\\Assignment 4\\\\dataset\\\\Train\"\n",
    "\n",
    "train_set = dataset(img_dir = path)\n",
    "\n",
    "train_loader = DataLoader(dataset = train_set, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18ebd959",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c4db62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cd630ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4eb19a11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 110/110 [00:09<00:00, 12.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1, Loss:104.572815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 110/110 [00:14<00:00,  7.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:2, Loss:130.820389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 110/110 [00:12<00:00,  9.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:3, Loss:99.222008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 110/110 [00:09<00:00, 11.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:4, Loss:126.529678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 110/110 [00:16<00:00,  6.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:5, Loss:103.035629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 110/110 [00:14<00:00,  7.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:6, Loss:67.514786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 110/110 [00:11<00:00,  9.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:7, Loss:62.583881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 110/110 [00:16<00:00,  6.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:8, Loss:94.166489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 110/110 [00:16<00:00,  6.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:9, Loss:78.799835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 110/110 [00:16<00:00,  6.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10, Loss:56.705467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 110/110 [00:13<00:00,  8.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:11, Loss:57.971195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 110/110 [00:09<00:00, 11.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:12, Loss:85.381927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 110/110 [00:09<00:00, 11.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:13, Loss:50.849785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 110/110 [00:09<00:00, 11.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:14, Loss:46.941994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 110/110 [00:09<00:00, 11.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:15, Loss:81.164429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 110/110 [00:09<00:00, 11.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:16, Loss:90.624046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 110/110 [00:09<00:00, 11.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:17, Loss:48.740295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 110/110 [00:09<00:00, 11.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:18, Loss:48.263474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 110/110 [00:09<00:00, 11.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:19, Loss:43.105839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 110/110 [00:09<00:00, 11.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:20, Loss:60.623535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 110/110 [00:09<00:00, 11.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:21, Loss:45.806664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 110/110 [00:09<00:00, 11.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:22, Loss:52.595612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 110/110 [00:09<00:00, 11.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:23, Loss:59.139187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 110/110 [00:09<00:00, 11.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:24, Loss:45.814358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 110/110 [00:09<00:00, 11.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:25, Loss:32.878094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 110/110 [00:09<00:00, 11.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:26, Loss:42.180889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 110/110 [00:09<00:00, 11.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:27, Loss:45.391171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 110/110 [00:09<00:00, 11.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:28, Loss:37.836121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 110/110 [00:09<00:00, 11.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:29, Loss:29.179348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 110/110 [00:09<00:00, 11.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:30, Loss:37.972500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data, targets) in enumerate(tqdm(train_loader)):\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "        scores, mean, standard_deviation = model(data)\n",
    "        \n",
    "        reconstruction_loss = criterion(targets, scores)\n",
    "        kl_divergence = -torch.sum(1 + torch.log(standard_deviation.pow(2)) - mean.pow(2) - standard_deviation.pow(2)) \n",
    "        loss = reconstruction_loss + kl_divergence\n",
    "  \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch:{epoch+1}, Loss:{loss.item():f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f4438f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PATH = \"E:\\\\College\\\\FCAI-4th Year\\\\First Term\\\\Generative Adversarial Networks\\\\Assginments\\\\Assignment 4\\\\VAE_weights.pth\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2aa630",
   "metadata": {},
   "source": [
    "Generate Images from test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2841ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "\n",
    "for i in range(10):\n",
    "    new_image = model.generate(device)\n",
    "    new_image = torch.squeeze(new_image, 0)\n",
    "    transform = T.ToPILImage()\n",
    "    img = transform(new_image)\n",
    "    img.save(\"E:\\\\College\\\\FCAI-4th Year\\\\First Term\\\\Generative Adversarial Networks\\\\Assginments\\\\Assignment 4\\\\Generated Images\\\\img\"+ str(i+1)+\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b6c093",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
