{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc4dd615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision \n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec3de22",
   "metadata": {},
   "source": [
    "This is a set of convenience functions to use instead of using the layers with thier hyperparamters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e191503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(channels_in, channels_out): \n",
    "    return nn.Conv2d(channels_in, channels_out, kernel_size = 3, stride = 1, padding = 'same', bias = False)\n",
    "\n",
    "def pool(): \n",
    "    return nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "\n",
    "def conv1x1(channels_in, channels_out): \n",
    "    return nn.Conv2d(channels_in, channels_out, kernel_size = 1, stride = 1, padding = 'same')\n",
    "\n",
    "def bn(channels_in): \n",
    "    return nn.BatchNorm2d(channels_in)\n",
    "\n",
    "def relu():\n",
    "    return nn.ReLU(inplace = True)\n",
    "\n",
    "def up():\n",
    "    return nn.Upsample(scale_factor = 2)\n",
    "\n",
    "def convUp(channels_in, channels_out): \n",
    "    return nn.Conv2d(channels_in, channels_out, kernel_size = 3, stride = 1, padding = 'same', bias = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b367bbe7",
   "metadata": {},
   "source": [
    "This a Sequential Module for a single block in the encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ddc7c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class down_Sample_Block(nn.Sequential):\n",
    "    def __init__(self, channels_in, channels_out):\n",
    "        super(down_Sample_Block, self).__init__()\n",
    "        self.add_module('conv1', conv(channels_in, channels_out))\n",
    "        self.add_module('conv2', conv(channels_out, channels_out))\n",
    "        self.add_module('conv3', conv(channels_out, channels_out))\n",
    "        self.add_module('conv4', conv(channels_out, channels_out))\n",
    "        self.add_module('norm', bn(channels_out))\n",
    "        self.add_module('relu', relu())\n",
    "        self.add_module('pool', pool())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9616dc",
   "metadata": {},
   "source": [
    "This a Sequential Module for a single block in the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2041a881",
   "metadata": {},
   "outputs": [],
   "source": [
    "class up_Sample_Block(nn.Sequential):\n",
    "    def __init__(self, channels_in, channels_out):\n",
    "        super(up_Sample_Block, self).__init__()\n",
    "        self.add_module('upSample', up())\n",
    "        self.add_module('conv1', convUp(channels_in, channels_out))\n",
    "        self.add_module('conv2', convUp(channels_out, channels_out))\n",
    "        self.add_module('conv3', convUp(channels_out, channels_out))\n",
    "        self.add_module('conv4', convUp(channels_out, channels_out))\n",
    "        self.add_module('norm', bn(channels_out))\n",
    "        self.add_module('relu', relu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc90fc93",
   "metadata": {},
   "source": [
    "Sequential module for the encoder block as a whole, it is designed to halve the height and width of the image, and double the number of channels, until it reaches (batch, channels, 1, 1).\n",
    "\n",
    "It is then passed through a conv_1x1 to reduce channels to 128, then it is flattened to remove the height and width dimensions (last two)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84810bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Sequential):\n",
    "    def __init__(self, encoder_output_length = 128):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.add_module('layer_1', down_Sample_Block(3, 8)) # 64\n",
    "        self.add_module('layer_2', down_Sample_Block(8, 16)) # 32\n",
    "        self.add_module('layer_3', down_Sample_Block(16, 32)) # 16\n",
    "        self.add_module('layer_4', down_Sample_Block(32, 64)) # 8\n",
    "        self.add_module('layer_5', down_Sample_Block(64, 128)) # 4\n",
    "        self.add_module('layer_6', down_Sample_Block(128, 256)) # 2\n",
    "        self.add_module('layer_7', down_Sample_Block(256, 256)) # 1\n",
    "\n",
    "        self.add_module('conv1x1', conv1x1(256, encoder_output_length))\n",
    "        self.add_module('flatten', nn.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020a9a1a",
   "metadata": {},
   "source": [
    "Module for the bottleneck block, it is the part where the mean and standard deviation layers are found, and where the reparameterization occurs.\n",
    "\n",
    "The output of the reconstruction has dimensions of (batch_size, channels), so inorder to make it suitable for the decoder, it is unsqueezed at dimensions 2 and 3 (the height and width dimensions are added again just like they were removed at the end of the encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "880294d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        latent_vec_len = 32,\n",
    "        encoder_output_length = 128,\n",
    "        decoder_input_length = 256\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.add_module('mean_layer', nn.Linear(encoder_output_length, latent_vec_len)),\n",
    "        self.add_module('standard_deviation_layer', nn.Linear(encoder_output_length, latent_vec_len)),\n",
    "        self.add_module('output_linear_layer', nn.Linear(latent_vec_len, decoder_input_length))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean = self.mean_layer(x)\n",
    "        standard_deviation = self.standard_deviation_layer(x)\n",
    "        epsilon = torch.randn_like(standard_deviation)\n",
    "        \n",
    "        x_reparameterized = mean + standard_deviation*epsilon\n",
    "        x_reconstructed = self.output_linear_layer(x_reparameterized)\n",
    "        \n",
    "        x_reconstructed = torch.unsqueeze(x_reconstructed, 2)\n",
    "        x_reconstructed = torch.unsqueeze(x_reconstructed, 3)\n",
    "        \n",
    "        return x_reconstructed, mean, standard_deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63a4d61",
   "metadata": {},
   "source": [
    "Sequential module for the decoder block as a whole, works in opposite fashion to the encoder.\n",
    "\n",
    "It is designed to take a tensor of dimensions (batch, channels, 1, 1) and double its height and width, and halve the number of channels, until it reaches (batch, 3, 128, 128)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd548f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Sequential):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.add_module('layer_1', up_Sample_Block(256, 256)) # 2\n",
    "        self.add_module('layer_2', up_Sample_Block(256, 128)) # 4\n",
    "        self.add_module('layer_3', up_Sample_Block(128, 64)) # 8\n",
    "        self.add_module('layer_4', up_Sample_Block(64, 32)) # 16\n",
    "        self.add_module('layer_5', up_Sample_Block(32, 16)) # 32\n",
    "        self.add_module('layer_6', up_Sample_Block(16, 8)) # 64\n",
    "        self.add_module('layer_7', up_Sample_Block(8, 3)) # 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776656df",
   "metadata": {},
   "source": [
    "Module for the VAE itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5122168",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.add_module('encoder', Encoder())\n",
    "        self.add_module('bottleneck', Bottleneck())\n",
    "        self.add_module('decoder', Decoder())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x, mean, standard_deviation = self.bottleneck(x)\n",
    "        x = self.decoder(x) \n",
    "        return x, mean, standard_deviation\n",
    "    \n",
    "    def generate(self, device):\n",
    "        with torch.no_grad():\n",
    "            x = torch.randn(1, 128)\n",
    "            x = x.to(device)\n",
    "            x, _, _ = self.bottleneck(x)\n",
    "            x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d59b3b46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (encoder): Encoder(\n",
       "    (layer_1): down_Sample_Block(\n",
       "      (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (conv3): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (conv4): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (norm): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer_2): down_Sample_Block(\n",
       "      (conv1): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (conv3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (conv4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer_3): down_Sample_Block(\n",
       "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (conv3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (conv4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer_4): down_Sample_Block(\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer_5): down_Sample_Block(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer_6): down_Sample_Block(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (conv4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer_7): down_Sample_Block(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (conv4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv1x1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (bottleneck): Bottleneck(\n",
       "    (mean_layer): Linear(in_features=128, out_features=32, bias=True)\n",
       "    (standard_deviation_layer): Linear(in_features=128, out_features=32, bias=True)\n",
       "    (output_linear_layer): Linear(in_features=32, out_features=256, bias=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (layer_1): up_Sample_Block(\n",
       "      (upSample): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (conv4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (layer_2): up_Sample_Block(\n",
       "      (upSample): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (layer_3): up_Sample_Block(\n",
       "      (upSample): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (layer_4): up_Sample_Block(\n",
       "      (upSample): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (conv3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (conv4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (layer_5): up_Sample_Block(\n",
       "      (upSample): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (conv1): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (conv3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (conv4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (layer_6): up_Sample_Block(\n",
       "      (upSample): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (conv1): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (conv3): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (conv4): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (norm): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (layer_7): up_Sample_Block(\n",
       "      (upSample): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (conv1): Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (conv3): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (conv4): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "      (norm): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VAE()\n",
    "\n",
    "# please change the path to that of the weights on your machine.\n",
    "\n",
    "PATH = \"E:\\\\College\\\\FCAI-4th Year\\\\First Term\\\\Generative Adversarial Networks\\\\Assginments\\\\Assignment 4\\\\VAE_weights.pth\"\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edefb599",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c4db62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2aa630",
   "metadata": {},
   "source": [
    "Generate Images from test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31657f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "\n",
    "model.generate(device)\n",
    "new_image = model.generate(device)\n",
    "new_image = torch.squeeze(new_image, 0)\n",
    "transform = T.ToPILImage()\n",
    "img = transform(new_image)\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9df556ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "import torchvision.transforms as T\n",
    "\n",
    "root = Tk()\n",
    "root.title('VAE Slider')\n",
    "root.geometry(\"400x400\")\n",
    "\n",
    "number_of_images = 0\n",
    "\n",
    "def generate():\n",
    "    number_of_images = slider.get()\n",
    "    for i in range(number_of_images):\n",
    "        model.generate(device)\n",
    "        new_image = model.generate(device)\n",
    "        new_image = torch.squeeze(new_image, 0)\n",
    "        transform = T.ToPILImage()\n",
    "        img = transform(new_image)\n",
    "        img.show()\n",
    "\n",
    "var = DoubleVar()\n",
    "slider = Scale(root, from_=1, to= 5, orient = HORIZONTAL)\n",
    "slider.get()\n",
    "slider.pack()\n",
    "\n",
    "button = Button(root, text=\"Generate\", command=generate)\n",
    "button.pack()\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b697975e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
